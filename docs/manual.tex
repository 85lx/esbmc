\documentclass{article}
\usepackage{url}
\usepackage{listings}
\begin{document}
\author{Jeremy Morse}
\title{A manual on some internals of ESBMC}
\maketitle
\section{Introduction and caveats}

This ``manual'' is supposed to be an introduction to how the ESBMC model
checkers internals are arranged and operate. It is not supposed to be a
comprehensive piece of documentation on the exact behaviour of particular
functions or facilities; nor will it ever, ever be up to date. Exact
documentation on a particular function or method should be written in
doxygen in headers; this documentation can be built to HTML by executing
\texttt{make doxygen} in the top level directory of ESBMCs source tree.

When referencing portions of code from within this manual, I'll probably
end up referring to class names and methods within them. Source files and
line numbers are liable to change, wheras the code layout of the project
is the least likely to suffer significant churn. The location of such a
class or method should be obvious from the context, or discoverable with
grep. Numerous references will also be made to the \textit{Internal
representation}, or \textit{irep} of something. This refers to how some piece
of data is structured or stored, see the 'Misc' section for detail.

A huge amount of the code base is derived from the CBMC project. CBMC is
open source (BSD 4-clause, ish), and available over SVN at
\url{http://www.cprover.org/svn/cbmc}. A large number of design decisions
are down to the development of CBMC; changes to ESBMC that cause
significant divergance from CBMCs design should be carefully thought
about, seeing how it's more mature than ESBMC. Likewise, code being
pulled in from CBMC should be examined to see whether it'll actually fit
into what ESBMC is doing nowdays.

All additional gunge, queries, complaints, to \url{jeremy.morse@gmail.com}

\section{Source tree structure}

In an order vaguely related to how ESBMCs execution order occurs, the
following describes the contents of directories in the source tree.

FIXME: This is ugly, make it a table.

\begin{description}
\item[docs] Directory for not-in-code documentation.
\item[papers] Self explanatory.
\item[scripts] Various scripts and auxilary files related to building ESBMC
               and dealing with things that aren't source files. Makefile
               scripts and release/binary manipulating scripts.
\item[esbmc] Top level model checking control code. Process entry point,
             option handling, general direction and invocation of the rest
             of the code base.
\item[langapi] Abstractions for handling input source files. Links a variety
               of global functions up to input-language-appropriate routines.
               Probably not massively necessary and could be ditched.
\item[ansi-c] Parser for ANSI-C software. Contains all code required to lex,
              parse, store as an AST, typecheck, and link, an input file.
\item[ansi-c/cpp] C preprocessor - an import of the Portable C Compilers
                  preprocessor, adapted to do what ESBMC needs.
\item[ansi-c/headers] C langauge headers to override system headers.
\item[ansi-c/library] C language implementations of various code libraries
                      that we seek to model.
\item[cpp] Parser for C++ language. Code for all compilation steps of C++.
\item[cpp/library] Implementation / models of various C++ template libraries.
\item[big-int] Arbitary length integer library. Used internally to avoid any
               kind of problems modelling large machine integers using small
               machine integers.
\item[goto-programs] Routines for general operations on GOTO instructions, as
                     well as all the code for converting a parsed AST into
                     GOTO instructions.
\item[pointer-analysis] Code for interpreting the execution of GOTO instructions
                        and the analysis of their effect upon pointer tracking.
                        Basically a static analysis of pointer assignment and
                        reachability. Also, contains code for resolving pointer
                        indirection in dereferences.
\item[goto-symex] Symbolic execution of GOTO instructions into an SSA program.
\item[solvers] Encoding of SSA program into SMT solver logic, and solving of
               the produced SMT formula.
\item[util] Miscellaneous functions, classes, and whatever to glue everything
            else together.
\item[regression] Regression tests for various different facets of ESBMC.
\end{description}

\section{Command line options}

Insert here, descriptions on command line options.

\section{Top level procedures}

Entry to the process starts (more or less) in the \texttt{doit} method of the
\texttt{cbmc\_parseoptionst} object. Various command line options are checked
for validity, before the \texttt{get\_goto\_program} method invokes the
frontend parsers to compile input source code into an AST. The AST for the
entire environment (all source files and libraries) is stored in a
\texttt{contextt} object, containing a list of symbols and their AST value.

The contents of the \texttt{contextt} object is passed to the
\texttt{goto\_convert} function, which produces a set of
\texttt{goto\_functiont}s corresponding to each function in the source language.
Each function contains little more than a \texttt{goto\_programt}, which
actually contain a list of instructions and some annotations.

With the set of GOTO functions, the \texttt{process\_goto\_program} method
applies the string abstraction transformation, the pointer analysis,
installs various pointer validity checks, and anything else that transforms
the source program into different instructions (such as LTL property monitors
or data race checking).

With these fixed-up goto functions, a \texttt{bmct} object is created and the
\texttt{run} method invoked on the functions. These functions are fed into a
\texttt{reachability\_treet} object, the primary interface to symbolic
execution. Within the \texttt{bmct::run} method, the symbolic execution engine
is asked to run through instructions creating an SSA program; potentially
several times if there are multiple threads involved. A result itself is a
\texttt{goto\_symext::symex\_resultt} containing the SSA program container and
a count of how many assertions remain to be verified in the program.

The SSA program is then optionally sliced; see the 'Misc' section for details.

A solver object is then created, a subclass of \texttt{bmct::solver\_base}
abstraction which solver to use. The SSA program is then fed to the solver,
which encodes it to SMT or whatever appropritate encoding it uses. It's then
asked to solve the equation, returning:
\begin{description}
\item[UNSATISFIABLE] The formula isn't satisfiable.
\item[SATISFIABLE] The formula is satisfiable.
\item[SMTLIB] A special case for printing the formula to a SMTLIB file.
\item[ERROR] Some error occured during solving.
\end{description}

Finally, if the formula is satisfiable, an error trace is created and printed.
Further details in the 'Misc' section.

\section{Source file parsing}

Code parsing is one of the untouched pastures of CBMC code, mostly. The ANSI-C
frontend is almost entirely like the original, while the C++ frontend has been
significantly developed by Manaus. The author is really familar with neither.
I'll talk about the ANSI-C frontend, then how the C++ frontend relates to it.

There are some significant conceptual steps involved. Firstly consider
the input and the output. Coming in is a C source file that must be preprocessed
and parsed - two fairly straightforward (although not easy) tasks. The top
levels of ESBMC then receive an AST representing the types and code structure
of the source file, which is more complex. The irep / structure of this data
is entirely undocumented and closely coupled between the parsers and the
\texttt{goto-programs} dir that converts it to GOTO instructions. However the
contents of this AST tends to be fairly high level language constructs,
for example \texttt{for} and \texttt{switch} statements. Refer to the method
\texttt{goto\_convertt:convert} for an idea of what kind of constructs these
are. The majority of the source file parsing code deals with converting between
the parse tree and the AST.

The preprocessing stage is contained in the \texttt{c\_preprocess} function.
In CBMC this used to offload preprocessing to the host preprocessor, however
our requirements have become more complicated since then. We now do
preprocessing using the preprocessor from the Portable C Compiler project
(which is BSD licensed). Unfortunately it wasn't designed with memory management
in mind, so ESBMC picks an output file, forks, calls the preprocessor to pump
outupt to the selected file, then exits the child process.

The complicated requirements from the preprocessor is that we generally want
code under test to have access to all headers on the host system, however we
also want to shoehorn our own types and functions in there --- for example the
glibc headers for assert have some obnoxious defines involved. Additionally
given how much lee-way standards give to libraries to define the format of
opaque data structures, we may need to define our own data structures to
avoid having to special case code for different operating systems. For example,
\texttt{pthread\_t}'s, \texttt{pthread\_mutex\_lock}'s and so forth differ
between operating systems, and we currently rely on on using Linux' pthread.h
header. The current fix for this is to intercept \texttt{\#include} statements
and read in an ESBMC specific header file from \texttt{ansi-c/headers} rather
than the system headers.

We parse C in the normal way; a flex tokenizer is defined, and a yacc grammar
defined which translate the input C into a parse tree. This needs no special
description. A class (\texttt{ansi\_c\_convertt}) takes the parse tree and
makes a simple translation to the format of the AST. The bulk of the work then
lies in the \textit{typechecking} phase. Here, the nasty parts of C that are
context-dependant\footnote{i.e., all of them} are fixed up. Factors such as
integer promotion, operation signedness, and actual correctness are
considered, and various casts or extensions are inserted. The output is stored
as a set of symbols with associated AST values in a \texttt{contextt} object.

After parsing and compilation is linking. In the past CBMC has just
tacked all libraries available onto the end of a source file being compiled,
and that's all. Nowdays the libraries are pre-compiled into a binary
representation of GOTO instructions, and linked in after typechecking of C
code, by copying in any symbol referred to from the compiled source files
that are in the compiled library files.

Finally there's the initialization of C global and static lifetime variables.
Seeing how the GOTO language is only made up of assignments, ish, their
initialization must be made by assignments too. So, an initial 'main' GOTO
function is synthesized from the \texttt{c\_main} and
\texttt{static\_lifetime\_init} functions. For each global variable an
assignment is emitted assigning the initial value to the global variable.

\section{GOTO programs}

This section covers both the GOTO program record itself, and the GOTO
instructions that make it up. Before launching into a description of these
records, it is important to understand that CBMC synthesizes the
\texttt{goto\_programt} class from the \texttt{goto\_program\_templatet}
template. This can lead to the most confusing and obscure error messages
if you do not realise that you're manipulating a template. From a design
point of view, the reason for this appears to be so that the types of
the GOTO program body could be parameterised; a decision that is almost
entirely without merit.

The \texttt{goto\_programt} class is more or less just a container for a
list of GOTO instructions (of class \texttt{goto\_programt::instructiont}).
It stores \textbf{no} additional information. Instead, all of its methods
perform operations on the contained instructions. Most of these relate
to the creation, insertion, and deletion of instructions, recalculating
their contents to be consistent after such a modification, and a few
special cases such as determining the successor instructions from a
particular instruction,

The actual GOTO instruction class itself's primary piece of data comes in
two flavours -- the \texttt{code} member or the \texttt{guard} member.
These store the internal representation of what the body of the instruction
\textit{is}. Exactly what the instruction means depends on the \texttt{type}
field, described thus:

\begin{description}
\item[GOTO] Jump from the current instruction to the instruction in the
\texttt{targets} field. If \texttt{guard} is not true, then the jump is
conditional, depending on the evaluation of \texttt{guard}. If \texttt{guard}
is true the jump to the target occurs; if not, execution continues to the next
instruction.
\item[ASSUME] Encode an assumption, stored in the \texttt{guard} field, to the
solver.
\item[ASSERT] Encode an assertion, stored in the \texttt{guard} field, to the
solver.
\item[OTHER] Catch-all instruction for storing special cases, enumerated below.
Identified by what kind of irep is stored in the \texttt{code} field.
\begin{description}
\item[cpp\_delete] Also \texttt{cpp\_delete[]}. Represents a deallocation of
some memory allocated by C++'s \texttt{new} or \texttt{new[]} operators.
\item[printf]\footnote{Yes, really} Represents a printf operation, for later
printing in a counterexample.
\item[decl] Represent declaration of a variable. Normally the declaration of
a variable is uninteresting as we only care about when it is initialized.
However in a loop where a variable is declared inside the loop block, it
transitions from being initialized to uninitialized when the loop iteration
finishes. Hence the importance of knowing where it is declared.
\item[nondet] Represent a nondeterministic value, from a \texttt{nondet\_*}
function call.
\item[asm] Inline assembly statement. Mercifully ignored.
\item[typeid] Fetch a C++ type ID record, I belive.
\end{description}
\item[SKIP] An ignored instruction.
\item[LOCATION] Previously caused a ``location'' SSA step to be recorded for
future tracking of the code path of the counterexample. Now redundant.
\item[END\_FUNCTION] End instruction of a function. Not the same as a return,
which can occur anywhere, but actually the final instruction in the list of
instructions.
\item[ATOMIC\_BEGIN] Self explanatory.
\item[ATOMIC\_END] Self explanatory.
\item[RETURN] Record a return statement, identifying the expression to return.
Stored in a ``return'' irep in the \texttt{code} field.
\item[ASSIGN] Self explanatory. An ``assign'' irep is stored in the
\texttt{code} field, identifying the left and right hand sides.
\item[DECL] Unused. Probably used to be, or was intended to be, the decl
irep from the OTHER instruction.
\item[DEAD] Unused. Comments say ``marks the end-of-live of a local variable''.
\item[FUNCTION\_CALL] A function call record; stores a function call irep in
the \texttt{code} field, which in turn records the left hand side of the call,
the arguments, and the target.
\item[THROW] Throw record; not familiar with this, but it'll result in some
kind of an assignment to a record of what's been thrown, and a jump to somewhere
else.
\item[THROW\_DECL] Record the start of a catch block for a particular type
of variable.
\item[THROW\_DECL] Record the end of a catch block for a particular type
of variable.
\end{description}

All behaviours of GOTO programs are described by lists of these instructions.
Additional annotations are stored with each instruction, for example the
\texttt{function} and \texttt{location} fields identify where in the source
files the instruction came from. The \texttt{targets} list contains a list
of where the instruction can jump to (which should only ever contain zero or
one target instructions).

\texttt{loop\_number} identifies a unique loop number for backwards
GOTO instructions. \texttt{target\_number} is a numeric ID that labels
the instruction within a function. This don't actually do anything, but
is printed in the textual representation of GOTO instructions to indicate
the targets of GOTOs.  There's also a set of local variable names, and
a globally unique instruction ID in \texttt{location\_number}.

That's the substance of instructions; more information on the interpretation
of them lies in the symbolic execution section.

\section{Pointer analysis}

The essence of the pointer analysis is a tracking of what pointer variables
exist in the GOTO code, and what they might point at. This occurs more than once
during each run of ESBMC. A static analysis of the instructions first attempts
to establish a set of all (lexical) variables that a particular (lexical)
variable in a function may point at. Then during symbolic execution, a similar
tracking maintains a set of (``runtime'') variables that an actual pointer
\textit{does} point at.

The static analysis is initiated from the GOTO program processing code in the
\texttt{cbmc\_parseoptionst} object. The high level analysis logic actually
lies in the \texttt{goto-programs} directory with the
\texttt{static\_analysist} and \texttt{abstract\_domain\_baset}
classes. Code in these classes call abstract methods to perform transformations 
between states as appropriate, over all GOTO instructions, to find a fixedpoint
where all values of the abstract domain have been discovered for all states.

The \texttt{value\_set\_analysist} and \texttt{value\_set\_domaint} classes
subclass the above two classes respectively to provide concrete
methods\footnote{I'm probably using all the wrong terminology here} for
tracking states of what pointer variables might point at. Most of the logic
itself lies in the latter class, storing both the actually tracking data
and forwarding transformation method calls to the appropriate objects.

A \texttt{value\_set\_domaint} contains only a \texttt{value\_sett} object.
That itself contains the pointer tracking map, which is, unsuprisingly,
string based. The core type is the \texttt{value\_sett::valuest} map,
where a string identifying a variable name maps to a
\texttt{value\_sett::entryt}, which stores a set of variables that may be
pointed at and the offset into them.

The string key of each of these entries is important -- When interpreting 
an assignment of a pointer value to a variable, we take the original variable
name being worked on and then interpret the left hand side, appending strings
to indicate /what/ part of the variable is being assigned to. To illustrate,
consider an assignment to the \texttt{bees} field of the following struct:
\begin{lstlisting}
struct face {
  void *bees[4];
};

int main() {
  struct face knees;
  knees.bees[0] = NULL;
  return 0;
}
\end{lstlisting}

Here, the fully qualified name of the variable we are assigning to is
\texttt{main::main::knees}, which becomes the starting point for the string
key in the value tracking map. We then interpret the left hand side of the
assignment, observe that we access the \texttt{bees} field, and so append the
text \texttt{.bees} to the key we are calculating. The next part of the left
hand side is the access to an element of the \texttt{bees} array, so we
append the text \texttt{[]} to the key we calculate. The final key is then
\texttt{main::main::knees.bees[]}. Observe that this approach allows every
variable in the program to have a unique key in the tracking map, except for
elements in an array --- we instead track what \textit{all} elements of the
array may point at, thus forming an overapproximation. The reasons for this
should be obvious.

The \texttt{value\_sett::entryt} class is responsible for tracking the target
variables that a pointer may point at. It stores a map between certain variable
names and \texttt{value\_sett::objectt}s. The presence of a variable name key
in the map indicates that the variable may be pointed at. The
\texttt{value\_sett::objectt} object records whether the offset into the
variable that is pointed at is nondeterministic or constant; and if fixed,
then what the offset is. (NB: the actual implementation of this stores
\texttt{symbol} ireps as the map keys. To optimise this, it uses a (global)
pooling technique to assign each irep an ID number; see the
\texttt{value\_sett::object\_numbering} object. The ID number is then used
as the key into the \texttt{value\_sett::entryt} map).

The \texttt{value\_sett} class also provides operations required in the course
of the static analysis, most importantly the ability to interpret an instruction
to record and update the tracking described above. The class can also merge
value set records into each other. This follows the obvious merging procedure;
however when the two tracking sets being merged have a pointer variable
that points at different offsets into the same data object, the merged
tracking set records a nondeterministic offset into that data object. This
forms an overapproximation of the offset into an object that a pointer points
at.

No attempt is made to track what I'll term \textit{funky} pointer assignments.
For example, if code deconstructs a pointer variable into bytes, then
reconstructs these bytes into a pointer value, we are unable to track
what the resulting pointer value points at. How to address this in the future
is an open question. The byte array memory models of other tools neatly
side-step this issue.

The static analysis process eventually reaches a fixedpoint state where we
have established all possible variables that may be pointed at byte pointer
variables. The contents of this analysis is then handed to an object of
class \texttt{goto\_program\_dereference}. This proceeds to enumerate all
GOTO instructions and attempts to perform all dereferences in the instruction.
Pointer safety assertions are then generated (see the section on dereferencing)
and inserted as ASSERT instructions prior to the dereferencing instruction.

The pointer analysis executed during symbolic execution uses the same records
and functions as the static analysis. While the static analysis attempts to find
all the variables a pointer might point at across all code paths, the symex
tracking instead tracks the set of all variables a pointer may point at in the
course of the current code path. The variables it tracks are also ``L1 renamed''
(see the section on Symbolic Execution).

It is speculated that the static analysis can be removed, and assertions
encoded on-the-fly when dereferences occur during symbolic execution. While
this might be a valid optimisation, the TACAS13 performance figures indicate
that execution time is dominated by symex, rather than the pointer
analysis\footnote{660 seconds ``GOTO processing'' compared to 20,000 seconds
``BMC time''}.

\section{Symbolic execution}
\section{SMT encoding}
\section{Solving and counterexamples}
\section{The inevitable 'misc'}
\subsection{Naming and namespaces}
\subsection{Dereferencing}
\subsection{Slicing}
\subsection{irep}
\subsection{Counterexamples}
\section{Conclusion}
\end{document}
