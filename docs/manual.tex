\documentclass{article}
\usepackage{url}
\begin{document}
\author{Jeremy Morse}
\title{A manual on some internals of ESBMC}
\maketitle
\section{Introduction and caveats}

This ``manual'' is supposed to be an introduction to how the ESBMC model
checkers internals are arranged and operate. It is not supposed to be a
comprehensive piece of documentation on the exact behaviour of particular
functions or facilities; nor will it ever, ever be up to date. Exact
documentation on a particular function or method should be written in
doxygen in headers; this documentation can be built to HTML by executing
\texttt{make doxygen} in the top level directory of ESBMCs source tree.

When referencing portions of code from within this manual, I'll probably
end up referring to class names and methods within them. Source files and
line numbers are liable to change, wheras the code layout of the project
is the least likely to suffer significant churn. The location of such a
class or method should be obvious from the context, or discoverable with
grep. Numerous references will also be made to the \textit{Internal
representation}, or \textit{irep} of something. This refers to how some piece
of data is structured or stored, see the 'Misc' section for detail.

A huge amount of the code base is derived from the CBMC project. CBMC is
open source (BSD 4-clause, ish), and available over SVN at
\url{http://www.cprover.org/svn/cbmc}. A large number of design decisions
are down to the development of CBMC; changes to ESBMC that cause
significant divergance from CBMCs design should be carefully thought
about, seeing how it's more mature than ESBMC. Likewise, code being
pulled in from CBMC should be examined to see whether it'll actually fit
into what ESBMC is doing nowdays.

All additional gunge, queries, complaints, to \url{jeremy.morse@gmail.com}

\section{Source tree structure}

In an order vaguely related to how ESBMCs execution order occurs, the
following describes the contents of directories in the source tree.

FIXME: This is ugly, make it a table.

\begin{description}
\item[docs] Directory for not-in-code documentation.
\item[papers] Self explanatory.
\item[scripts] Various scripts and auxilary files related to building ESBMC
               and dealing with things that aren't source files. Makefile
               scripts and release/binary manipulating scripts.
\item[esbmc] Top level model checking control code. Process entry point,
             option handling, general direction and invocation of the rest
             of the code base.
\item[langapi] Abstractions for handling input source files. Links a variety
               of global functions up to input-language-appropriate routines.
               Probably not massively necessary and could be ditched.
\item[ansi-c] Parser for ANSI-C software. Contains all code required to lex,
              parse, store as an AST, typecheck, and link, an input file.
\item[ansi-c/cpp] C preprocessor - an import of the Portable C Compilers
                  preprocessor, adapted to do what ESBMC needs.
\item[ansi-c/headers] C langauge headers to override system headers.
\item[ansi-c/library] C language implementations of various code libraries
                      that we seek to model.
\item[cpp] Parser for C++ language. Code for all compilation steps of C++.
\item[cpp/library] Implementation / models of various C++ template libraries.
\item[big-int] Arbitary length integer library. Used internally to avoid any
               kind of problems modelling large machine integers using small
               machine integers.
\item[goto-programs] Routines for general operations on GOTO instructions, as
                     well as all the code for converting a parsed AST into
                     GOTO instructions.
\item[pointer-analysis] Code for interpreting the execution of GOTO instructions
                        and the analysis of their effect upon pointer tracking.
                        Basically a static analysis of pointer assignment and
                        reachability. Also, contains code for resolving pointer
                        indirection in dereferences.
\item[goto-symex] Symbolic execution of GOTO instructions into an SSA program.
\item[solvers] Encoding of SSA program into SMT solver logic, and solving of
               the produced SMT formula.
\item[util] Miscellaneous functions, classes, and whatever to glue everything
            else together.
\item[regression] Regression tests for various different facets of ESBMC.
\end{description}

\section{Command line options}

Insert here, descriptions on command line options.

\section{Top level procedures}

Entry to the process starts (more or less) in the \texttt{doit} method of the
\texttt{cbmc\_parseoptionst} object. Various command line options are checked
for validity, before the \texttt{get\_goto\_program} method invokes the
frontend parsers to compile input source code into an AST. The AST for the
entire environment (all source files and libraries) is stored in a
\texttt{contextt} object, containing a list of symbols and their AST value.

The contents of the \texttt{contextt} object is passed to the
\texttt{goto\_convert} function, which produces a set of
\texttt{goto\_functiont}s corresponding to each function in the source language.
Each function contains little more than a \texttt{goto\_programt}, which
actually contain a list of instructions and some annotations.

With the set of GOTO functions, the \texttt{process\_goto\_program} method
applies the string abstraction transformation, the pointer analysis,
installs various pointer validity checks, and anything else that transforms
the source program into different instructions (such as LTL property monitors
or data race checking).

With these fixed-up goto functions, a \texttt{bmct} object is created and the
\texttt{run} method invoked on the functions. These functions are fed into a
\texttt{reachability\_treet} object, the primary interface to symbolic
execution. Within the \texttt{bmct::run} method, the symbolic execution engine
is asked to run through instructions creating an SSA program; potentially
several times if there are multiple threads involved. A result itself is a
\texttt{goto\_symext::symex\_resultt} containing the SSA program container and
a count of how many assertions remain to be verified in the program.

The SSA program is then optionally sliced; see the 'Misc' section for details.

A solver object is then created, a subclass of \texttt{bmct::solver\_base}
abstraction which solver to use. The SSA program is then fed to the solver,
which encodes it to SMT or whatever appropritate encoding it uses. It's then
asked to solve the equation, returning:
\begin{description}
\item[UNSATISFIABLE] The formula isn't satisfiable.
\item[SATISFIABLE] The formula is satisfiable.
\item[SMTLIB] A special case for printing the formula to a SMTLIB file.
\item[ERROR] Some error occured during solving.
\end{description}

Finally, if the formula is satisfiable, an error trace is created and printed.
Further details in the 'Misc' section.

\section{Source file parsing}

Code parsing is one of the untouched pastures of CBMC code, mostly. The ANSI-C
frontend is almost entirely like the original, while the C++ frontend has been
significantly developed by Manaus. The author is really familar with neither.
I'll talk about the ANSI-C frontend, then how the C++ frontend relates to it.

There are some significant conceptual steps involved. Firstly consider
the input and the output. Coming in is a C source file that must be preprocessed
and parsed - two fairly straightforward (although not easy) tasks. The top
levels of ESBMC then receive an AST representing the types and code structure
of the source file, which is more complex. The irep / structure of this data
is entirely undocumented and closely coupled between the parsers and the
\texttt{goto-programs} dir that converts it to GOTO instructions. However the
contents of this AST tends to be fairly high level language constructs,
for example \texttt{for} and \texttt{switch} statements. Refer to the method
\texttt{goto\_convertt:convert} for an idea of what kind of constructs these
are. The majority of the source file parsing code deals with converting between
the parse tree and the AST.

The preprocessing stage is contained in the \texttt{c\_preprocess} function.
In CBMC this used to offload preprocessing to the host preprocessor, however
our requirements have become more complicated since then. We now do
preprocessing using the preprocessor from the Portable C Compiler project
(which is BSD licensed). Unfortunately it wasn't designed with memory management
in mind, so ESBMC picks an output file, forks, calls the preprocessor to pump
outupt to the selected file, then exits the child process.

The complicated requirements from the preprocessor is that we generally want
code under test to have access to all headers on the host system, however we
also want to shoehorn our own types and functions in there --- for example the
glibc headers for assert have some obnoxious defines involved. Additionally
given how much lee-way standards give to libraries to define the format of
opaque data structures, we may need to define our own data structures to
avoid having to special case code for different operating systems. For example,
\texttt{pthread\_t}'s, \texttt{pthread\_mutex\_lock}'s and so forth differ
between operating systems, and we currently rely on on using Linux' pthread.h
header. The current fix for this is to intercept \texttt{\#include} statements
and read in an ESBMC specific header file from \texttt{ansi-c/headers} rather
than the system headers.

We parse C in the normal way; a flex tokenizer is defined, and a yacc grammar
defined which translate the input C into a parse tree. This needs no special
description. A class (\texttt{ansi\_c\_convertt}) takes the parse tree and
makes a simple translation to the format of the AST. The bulk of the work then
lies in the \textit{typechecking} phase. Here, the nasty parts of C that are
context-dependant\footnote{i.e., all of them} are fixed up. Factors such as
integer promotion, operation signedness, and actual correctness are
considered, and various casts or extensions are inserted. The output is stored
as a set of symbols with associated AST values in a \texttt{contextt} object.

After parsing and compilation is linking. In the past CBMC has just
tacked all libraries available onto the end of a source file being compiled,
and that's all. Nowdays the libraries are pre-compiled into a binary
representation of GOTO instructions, and linked in after typechecking of C
code, by copying in any symbol referred to from the compiled source files
that are in the compiled library files.

Finally there's the initialization of C global and static lifetime variables.
Seeing how the GOTO language is only made up of assignments, ish, their
initialization must be made by assignments too. So, an initial 'main' GOTO
function is synthesized from the \texttt{c\_main} and
\texttt{static\_lifetime\_init} functions. For each global variable an
assignment is emitted assigning the initial value to the global variable.

\section{GOTO instructions}
\section{Pointer analysis}
\section{Symbolic execution}
\section{SMT conversion}
\section{SMT encoding}
\section{Solving and counterexamples}
\section{The inevitable 'misc'}
\subsection{Slicing}
\subsection{irep}
\subsection{Counterexamples}
\section{Conclusion}
\end{document}
